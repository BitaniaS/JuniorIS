{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Importing required libraries \n",
    "# from tensorflow.python.ops.ragged.ragged_tensor import RaggedTensorSpec as MyRaggedTensorSpec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "# import keras \n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from keras.callbacks import CSVLogger \n",
    "import tensorflow as tf\n",
    "from keras.utils import get_custom_objects\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list=os.listdir('./PageSegData1/PageImg')\n",
    "image_list=[filename.split(\".\")[0]for filename in image_list] #use os.path.splittext() as an alternate \n",
    "random.shuffle(image_list)\n",
    "file_train=image_list[0:int(0.70*len(image_list))]\n",
    "file_valid=image_list[int(0.70*len(image_list)): int(0.90*len(image_list))]\n",
    "file_test=image_list[int(0.90*len(image_list)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define val_accuracy as a custom metric\n",
    "\n",
    "# Define val_accuracy as a custom metric\n",
    "def val_accuracy(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    accuracy = tf.keras.metrics.binary_accuracy(y_true, y_pred)\n",
    "    return tf.reduce_mean(accuracy)\n",
    "\n",
    "val_accuracy_metric = tf.keras.metrics.MeanMetricWrapper(\n",
    "    name='val_accuracy', fn=val_accuracy, dtype=tf.float32\n",
    ")\n",
    "\n",
    "# # Register the custom metric with Keras\n",
    "# get_custom_objects().update({'val_accuracy': val_accuracy_metric})\n",
    "\n",
    "# def val_loss(y_true, y_pred):\n",
    "#     y_pred = tf.round(y_pred)\n",
    "#     accuracy = tf.keras.metrics.binary_accuracy(y_true, y_pred)\n",
    "#     return tf.reduce_mean(loss)\n",
    "\n",
    "# val_loss_metric = tf.keras.metrics.MeanMetricWrapper(\n",
    "#     name='val_loss', fn=val_loss, dtype=tf.float32\n",
    "# )\n",
    "\n",
    "# # Register the custom metric with Keras\n",
    "# get_custom_objects().update({'val_accuracy': val_accuracy_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function Definitions \n",
    "'''\n",
    "This function takes two images as input, displays them side by side, \n",
    "and titles them \"Image\" and \"Segmented Image\". \n",
    "This function is used later in the script to display images.\n",
    "'''\n",
    "def visualize(img,seg_img):\n",
    "    \"\"\"\n",
    "    Visualizes image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(seg_img,cmap='gray')\n",
    "    plt.title('Segmented Image')\n",
    "    # plt.show()\n",
    "\n",
    "'''\n",
    "This creates a segmentation mask where each pixel in the image is assigned a label or category. \n",
    "In this case, all the pixels are initially labeled as 0, indicating that they do not belong to any category.\n",
    "'''\n",
    "\n",
    "#to convert the segmentation mask into one-hot encoded representation \n",
    "def get_segmented_img(img,n_classes): # also known as binary segmentation mask \n",
    "\n",
    "    seg_labels=np.zeros((512,512,1)) # creating a Numpy Array width * height*channels \n",
    "    img=cv2.resize(img,(512,512)) #resize img to height and width of 512 (same case as the gray scale thingy, do I need to preprocess ?)\n",
    "    \n",
    "    img=img[:,:,0] # i'm not sure if this line converts it to grey scale or not ( do I need to do the preprocessing part ? )\n",
    "     # selecting only the first channel of the resized image array this effectively converts it to grayscale \n",
    "    # Image preprocessing needs to happen to convert img to gray scale\n",
    "    # The preprocessing function can perform the following (color space conversion, filtering and etc). \n",
    "    # Look into the function I already have and also the research paper which talks about the best methods for preprocessing images \n",
    "\n",
    "\n",
    "    cl_list=[0,24] #NOT SURE IF I NEED THIS\n",
    "\n",
    "    \n",
    "    seg_labels[:,:,0]=(img==0).astype(int) # if the pixels in img are not 0 then set the corresponding pixel in \n",
    "    # seg_label to 1 so all non zero pixel in img have a mask of 1 and all zero pixel in img have a mask of 0\n",
    "    \n",
    "    # cv2.imshow('Segmentation Mask', seg_labels)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return seg_labels\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img=cv2.resize(img,(320,320))\n",
    "    return img\n",
    "\n",
    "def label_isolation(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Otsu's thresholding method\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Convert the binary mask to a 3-channel image\n",
    "    mask = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "    # # Convert the image to a tensor\n",
    "    # image = tf.convert_to_tensor(image)\n",
    "\n",
    "    # # Threshold the image\n",
    "    # threshold = tf.constant(0.0)\n",
    "    # mask = tf.greater(image, threshold)\n",
    "    # mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    return mask\n",
    "# batch generator \n",
    "\n",
    "def batch_generator(filelist,n_classes,batch_size,augment_v):\n",
    "  datagen = ImageDataGenerator(\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.1, #shifts the width of all the pixels of the image keza teg lay yalew to the beginning part yehedal\n",
    "      height_shift_range=0.1, #distorts image a bit by shifting some pixels along a given axis\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='constant',\n",
    "      cval=0.0/255.0,\n",
    "    #means that the constant value used for padding or filling empty pixels \n",
    "    #in the image will be black, and that the value will be scaled to the \n",
    "    # range between 0 and 1 for compatibility with certain deep learning frameworks.\n",
    "      preprocessing_function=None)\n",
    "\n",
    "  while True:\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in range(batch_size):\n",
    "      fn=random.choice(filelist)\n",
    "      img=cv2.imread(f'./PageSegData1/PageImg/{fn}.JPG',0)\n",
    "      # img = np.zeros((img2.shape, img2.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "      # # Set all three channels to the grayscale values\n",
    "      # img[:, :, 0] = img2\n",
    "      # img[:, :, 1] = img2\n",
    "      # img[:, :, 2] = img2\n",
    "\n",
    "\n",
    "      ret,img=cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "      img=cv2.resize(img,(512,512))\n",
    "      img=np.expand_dims(img,axis=-1)\n",
    "      img=img/255\n",
    "\n",
    "      seg=cv2.imread(f'./PageSegData1/PageSeg/{fn}_mask.png',1)\n",
    "      seg=get_segmented_img(seg,2)\n",
    "\n",
    "      if augment_v:\n",
    "          seed = np.random.randint(1,100000)\n",
    "          img = datagen.random_transform(img, seed=seed)\n",
    "          seg = datagen.random_transform(seg, seed=seed)\n",
    "\n",
    "      X.append(img)\n",
    "      Y.append(seg)\n",
    "    yield np.array(X),np.array(Y)\n",
    "\n",
    "def plot_epochMetric(history,metric):\n",
    "  train_metrics = history.history[metric]\n",
    "  val_metrics = history.history['val_'+metric]\n",
    "  epochs = range(1, len(train_metrics) + 1)\n",
    "  plt.plot(epochs, train_metrics)\n",
    "  plt.plot(epochs, val_metrics)\n",
    "  plt.title('Training and validation '+ metric)\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "  # plt.show()\n",
    "\n",
    "# def plot_epochMetric(history,metric):\n",
    "#     train_metrics = history.history[metric]\n",
    "#     val_metrics = history.history['val_'+metric]\n",
    "#     epochs = range(1, len(train_metrics) + 1)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(epochs, train_metrics)\n",
    "#     ax.plot(epochs, val_metrics)\n",
    "#     ax.set_title('Training and validation '+ metric)\n",
    "#     ax.set_xlabel(\"Epochs\")\n",
    "#     ax.set_ylabel(metric)\n",
    "#     ax.legend([\"train_\"+metric, 'val_'+metric])\n",
    "#     canvas = FigureCanvas(fig)\n",
    "#     canvas.draw()\n",
    "#     plot_image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "#     plot_image = plot_image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "#     # plt.close(fig)\n",
    "#     return plot_image  \n",
    "\n",
    "  \n",
    "      #  train_metrics = history.history[metric]\n",
    "      #  val_metrics = history.history['val_'+metric]\n",
    "      #  epochs = range(1, len(train_metrics) + 1)\n",
    "      #  fig,ax = plt.subplots()\n",
    "      #  ax.plt.plot(epochs, train_metrics)\n",
    "      #  ax.plt.plot(epochs, val_metrics)\n",
    "      #  ax.plt.title('Training and validation '+ metric)\n",
    "      #  ax.set_xlabel(\"Epochs\")\n",
    "      #  ax.set_ylabel(metric)\n",
    "      #  ax.legend([\"train_\"+metric, 'val_'+metric])\n",
    "      # #  plt.xlabel(\"Epochs\")\n",
    "      # #  plt.ylabel(metric)\n",
    "      # #  plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "      #  canvas = FigureCanvas(fig)\n",
    "      #  canvas.draw()\n",
    "      #  plot_image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "      #  plot_image = plot_image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "      #  return plot_image\n",
    "       \n",
    "      #  size = fig.get_size_inches()*fig.dpi # size in pixels\n",
    "      #  matplotlib.rc('figure', figsize=(10, 5))\n",
    "      #  print(size)\n",
    "       \n",
    "\n",
    "       \n",
    "      #  if filename is not None:\n",
    "      #   # plt.savefig(filename, dpi=100, bbox_inches='tight', format='jpg')\n",
    "      #  else:\n",
    "      #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = \"./PageSegData1/PageSeg/3_mask.png\"\n",
    "\n",
    "image = cv2.imread(path)\n",
    "result = get_segmented_img(image,2)\n",
    "result2 = label_isolation(image)\n",
    "\n",
    "visualize(image,result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #splitting dataset\n",
    "\n",
    "# random.shuffle(image_list)\n",
    "# file_train=image_list[0:int(0.75*len(image_list))]\n",
    "# file_valid=image_list[int(0.70*len(image_list)): int(0.90*len(image_list))]\n",
    "# file_test=image_list[int(0.90*len(image_list)):]\n",
    "\n",
    "# #important variables\n",
    "# # metric =  ['accuracy']\n",
    "# input_size = (512,512,1)\n",
    "\n",
    "\n",
    "# # params = {\n",
    "# #     'learning_rate': [1e-3, 1e-4, 1e-5], \n",
    "# #     'batch_size': [4,8,16],\n",
    "# #     'epochs': [3, 5, 7],\n",
    "# #     # 'filters': [8, 16, 32],\n",
    "# #     'Steps':[100,150,200],\n",
    "# #     'Weight_decay' : [0.00001, 0.0001, 0.001],\n",
    "# #     # 'step' :[100,150,200],\n",
    "# #     'Augment_Data': [True,False]\n",
    "# # }\n",
    "\n",
    "# val_loss_list = []\n",
    "# val_acc_list = []\n",
    "# # f1_list = []\n",
    "# # prec_list = []\n",
    "# # rec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 320, 320, 1)  10          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 320, 320, 1)  10          ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 160, 160, 1)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 160, 160, 4)  40          ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 160, 160, 4)  148         ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 80, 80, 4)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 80, 80, 8)    296         ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 80, 80, 8)    584         ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 40, 40, 8)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 80, 80, 8)    0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 80, 80, 8)    264         ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 80, 80, 16)   0           ['conv2d_6[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 80, 80, 8)    1160        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 160, 160, 8)  0          ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 160, 160, 4)  132         ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 160, 160, 8)  0           ['conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 160, 160, 4)  292         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 320, 320, 4)  0          ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 320, 320, 1)  17          ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 320, 320, 2)  0           ['conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 320, 320, 1)  19          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 320, 320, 1)  2           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,974\n",
      "Trainable params: 2,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Actuall model \n",
    "# def unet(l2_weight = 0.02):\n",
    "#     inputs = Input(input_size)\n",
    "#     conv1 = Conv2D(1, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(inputs)\n",
    "#     conv1 = Conv2D(1, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     # pool1 = Dropout(dropout_rate)(pool1)\n",
    "\n",
    "#     conv2 = Conv2D(4, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(pool1)\n",
    "#     conv2 = Conv2D(4, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     # pool2 = Dropout(dropout_rate)(pool2)\n",
    "\n",
    "#     # conv3 = Conv2D(8, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(pool2)\n",
    "#     conv3 = Conv2D(8, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(pool2)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     # pool3 = Dropout(dropout_rate)(pool3)\n",
    "\n",
    "#     up4 = UpSampling2D(size=(2, 2))(pool3)\n",
    "#     up4 = Conv2D(8, 2, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up4)\n",
    "#     # up4 = Concatenate()([up4, conv3])\n",
    "#     up4 = Conv2D(8, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up4)\n",
    "#     # up4 = Dropout(dropout_rate)(up4)\n",
    "\n",
    "#     up5 = UpSampling2D(size=(2, 2))(up4)\n",
    "#     up5 = Conv2D(4, 2, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up5)\n",
    "#     up5 = Concatenate()([up5, conv2])\n",
    "#     up5 = Conv2D(4, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up5)\n",
    "#     # up5 = Dropout(dropout_rate)(up5)\n",
    "\n",
    "#     up6 = UpSampling2D(size=(2, 2))(up5)\n",
    "#     up6 = Conv2D(1, 2, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up6)\n",
    "#     up6 = Concatenate()([up6, conv1])\n",
    "#     up6 = Conv2D(1, 3, activation='relu', padding='same', kernel_regularizer=l2(l2_weight))(up6)\n",
    "#     # up6 = Dropout(dropout_rate)(up6)\n",
    "\n",
    "#     outputs = Conv2D(1, 1, activation='sigmoid')(up6)\n",
    "\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "\n",
    "def unet():\n",
    "    input_shape = (320, 320, 1)     \n",
    "    inputs = Input(input_shape)\n",
    " \n",
    "\n",
    "    conv1 = Conv2D(1, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(1, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(4, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(4, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(8, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(8, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    up4 = UpSampling2D(size=(2, 2))(pool3)\n",
    "    up4 = Conv2D(8, 2, activation='relu', padding='same')(up4)\n",
    "    up4 = Concatenate()([up4, conv3])\n",
    "    up4 = Conv2D(8, 3, activation='relu', padding='same')(up4)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(up4)\n",
    "    up5 = Conv2D(4, 2, activation='relu', padding='same')(up5)\n",
    "    up5 = Concatenate()([up5, conv2])\n",
    "    up5 = Conv2D(4, 3, activation='relu', padding='same')(up5)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(up5)\n",
    "    up6 = Conv2D(1, 2, activation='relu', padding='same')(up6)\n",
    "    up6 = Concatenate()([up6, conv1])\n",
    "    up6 = Conv2D(1, 3, activation='relu', padding='same')(up6)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='softmax')(up6)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "     \n",
    "    return model\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model = unet()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining metrics and hyperparameters\n",
    "batch_s = 16\n",
    "test_gen = batch_generator(file_train,2,batch_s,True)\n",
    "valid_gen = batch_generator(file_valid,2,batch_s,False)\n",
    "n_epoch = 3\n",
    "steps = 100\n",
    "# steps_pre_epoch  = len(test_gen) // batch_s\n",
    "# validation_steps = len(valid_gen) // batch_s\n",
    "metric =  ['accuracy']\n",
    "#defining the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "#training the model\n",
    "mc = ModelCheckpoint('best_weight_epoch{epoch:03d}.h5', monitor=' precision, recall',\n",
    "                             save_weights_only=True)\n",
    "model.compile(optimizer = Adam(learning_rate= 1e-4), loss = 'binary_crossentropy', metrics= metric)\n",
    "     \n",
    "        # csv_logger = CSVLogger('training_history.csv',append = True)\n",
    "history = model.fit(test_gen,epochs=n_epoch,steps_per_epoch=steps,validation_data=valid_gen,validation_steps=5,\n",
    "          callbacks=[mc,early_stop],shuffle=1)\n",
    "# model.save('my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(f'./PageSegData1/PageImg/60.JPG',0)\n",
    "ret,img=cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "img=cv2.resize(img,(512,512))\n",
    "img= np.expand_dims(img,axis=-1)\n",
    "img=np.expand_dims(img,axis=0)\n",
    "pred=model.predict(img)\n",
    "pred=np.squeeze(np.squeeze(pred,axis=0),axis=-1)\n",
    "plt.imshow(pred,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "# from gradio.inputs import Group\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "from PIL import Image\n",
    "\n",
    "# def process_figure(fig):\n",
    "#     # create a canvas for the figure\n",
    "#     canvas = FigureCanvasAgg(fig)\n",
    "\n",
    "#     # render the figure as a numpy array\n",
    "#     canvas.draw()\n",
    "#     data = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "#     data = data.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "#     # convert the numpy array to a PIL image\n",
    "#     image = Image.fromarray(data)\n",
    "\n",
    "#     return image\n",
    "\n",
    "# model = tf. keras.models.load_model('./my_model')\n",
    "# params = {\n",
    "learning_rate = [1e-3, 1e-4, 1e-5], \n",
    "batch_size =  [4,8,16],\n",
    "epochs = [5,10],\n",
    "    # 'filters': [8, 16, 32],\n",
    "Steps =[100,150,200],\n",
    "#     'Weight_decay' : gr.inputs.CheckboxGroup[ 0.0001, 0.001],\n",
    "    # 'step' :[100,150,200],\n",
    "Augment_Data =  ['True','False']\n",
    "\n",
    "# input_image = gr.inputs.Image(shape=(512, 512))\n",
    "\n",
    "learning_rate = gr.Radio([1e-3, 1e-4, 1e-5], label = \"Select a Learning Rate\")\n",
    "batch_size= gr.Radio([4,8,16],label= \"Select a Batch Size\")\n",
    "epochs = gr.Radio([2,5,10,20,30], label = \"Select an Epoch Value\")\n",
    "Steps = gr.Radio([100,150,200], label = \"Select a Step Value\")\n",
    "Augment_Data =  gr.Radio( [\"True\",\"False\"], label = \"Do you want to augment the data\")  \n",
    "\n",
    "def result_display (learning_rate,batch_size,epochs,Steps,Augment_Data):    \n",
    "           \n",
    "        batch_s = batch_size\n",
    "        n_epoch = epochs\n",
    "        steps = Steps\n",
    "        augment_v = Augment_Data\n",
    "        # dims = (320,320)\n",
    "        \n",
    "        model = unet()\n",
    "            # model.summary()\n",
    "            # # batch_s = 16\n",
    "        test_gen = batch_generator(file_train,2,batch_s,augment_v)\n",
    "        valid_gen = batch_generator(file_valid,2,batch_s,augment_v)\n",
    "            # print(\"YES 1 \")\n",
    "            # n_epoch = 10\n",
    "            # steps = 100\n",
    "            # steps_pre_epoch  = len(test_gen) // batch_s\n",
    "            # validation_steps = len(valid_gen) // batch_s\n",
    "        metric =  ['accuracy']\n",
    "            #defining the early stopping callback\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "            #training the model\n",
    "        mc = ModelCheckpoint('best_weight_epoch{epoch:03d}.h5', monitor=' precision, recall',\n",
    "                                        save_weights_only=True)\n",
    "            # print(\"YES 2 \")\n",
    "        model.compile(optimizer = Adam(learning_rate= learning_rate), loss = 'binary_crossentropy', metrics= metric)\n",
    "            # print(\"YES 3 \")\n",
    "                    # csv_logger = CSVLogger('training_history.csv',append = True)\n",
    "        history = model.fit(test_gen,epochs=n_epoch,steps_per_epoch=steps,validation_data=valid_gen,validation_steps=5,\n",
    "                    callbacks=[mc,early_stop],shuffle=1)\n",
    "        \n",
    "        # model.save('my_model')\n",
    "        \n",
    "\n",
    "        output_image1 = plot_epochMetric(history, 'accuracy')\n",
    "        \n",
    "        # output_image1f = process_figure(output_image1)\n",
    "    \n",
    "        # output_image2 = plot_epochMetric(history, 'loss')\n",
    "        # output_image2f = process_figure(output_image2).\n",
    "        # image_format = output_image1.format\n",
    "\n",
    "        # print(\"THE IMAGE FORMAT IS \",image_format)\n",
    "        return output_image1\n",
    "\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=result_display, \n",
    "                     inputs=[   gr.Radio([1e-3, 1e-4, 1e-5], label = \"Select a Learning Rate\"),\n",
    "                                gr.Radio([4,8,16],label= \"Select a Batch Size\"),\n",
    "                                gr.Radio([2,5,10,20,30], label = \"Select an Epoch Value\"),\n",
    "                                gr.Radio([100,150,200], label = \"Select a Step Value\"),\n",
    "                                gr.Radio( [\"True\",\"False\"], label = \"Do you want to augment the data\") ], \n",
    "                     outputs=gr.Image(shape=(320,320)))\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[39m=\u001b[39m plot_epochMetric(history,\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "img = plot_epochMetric(history,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open('image.jpg')\n",
    "\n",
    "# Get the format of the image\n",
    "image_format = image.format\n",
    "\n",
    "# Print the format of the image\n",
    "print('Image format:', image_format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
